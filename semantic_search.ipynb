{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dawit-melka/ICog-Labs/blob/main/semantic_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znVKd4yBtTnq"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_K9IhigsGyo"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/dawit-melka/ICog-Labs.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmU_TysZy-MX",
        "outputId": "b24b37cb-d36a-4849-a5cf-9fccbe101f04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ICog-Labs\n"
          ]
        }
      ],
      "source": [
        "%cd ICog-Labs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-YjfEKJzFUZ"
      },
      "outputs": [],
      "source": [
        "%cd Semantic Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdIv8SI-zucO"
      },
      "outputs": [],
      "source": [
        "!pip install fuzzywuzzy\n",
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Lf3dzwFzLA4"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import os\n",
        "import nltk\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from fuzzywuzzy import fuzz\n",
        "\n",
        "# import voyageai\n",
        "# from voyageai import get_embeddings, get_embedding\n",
        "\n",
        "from data.questions_and_answers import questions, answers\n",
        "nltk.download('punkt')  # Uncomment if not already downloaded\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "J5W4ZtU4zdRm"
      },
      "outputs": [],
      "source": [
        "def load_input_data(file_path):\n",
        "    \"\"\"\n",
        "    Load input data from a file.\n",
        "\n",
        "    Parameters:\n",
        "    - file_path (str): Path to the input file.\n",
        "\n",
        "    Returns:\n",
        "    - str: Contents of the file.\n",
        "    \"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        data = f.read()\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "njnCbNtZ0E_D"
      },
      "outputs": [],
      "source": [
        "def convert_to_sentences(text):\n",
        "    \"\"\"\n",
        "    Convert a text into a list of sentences.\n",
        "\n",
        "    Parameters:\n",
        "    - text (str): Input text.\n",
        "\n",
        "    Returns:\n",
        "    - list: List of sentences.\n",
        "    \"\"\"\n",
        "    return nltk.sent_tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LZiJGabX0K0b"
      },
      "outputs": [],
      "source": [
        "def download_models(model_names):\n",
        "    \"\"\"\n",
        "    Download sentence transformer models.\n",
        "\n",
        "    Parameters:\n",
        "    - model_names (list): List of model names to download.\n",
        "    \"\"\"\n",
        "    for model_name in model_names:\n",
        "        model = SentenceTransformer(model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "w_oOATtR0Pp1"
      },
      "outputs": [],
      "source": [
        "def compute_similarity_scores(query_emb, doc_emb):\n",
        "    \"\"\"\n",
        "    Compute similarity scores between a query and document embeddings.\n",
        "\n",
        "    Parameters:\n",
        "    - query_emb (numpy array): Embedding of the query.\n",
        "    - doc_emb (numpy array): Embeddings of the documents.\n",
        "\n",
        "    Returns:\n",
        "    - list: Similarity scores.\n",
        "    \"\"\"\n",
        "    return util.dot_score(query_emb, doc_emb)[0].cpu().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BdgH6wzFExvA"
      },
      "outputs": [],
      "source": [
        "def check_similarity(sentence1, sentence2):\n",
        "    similarity_ratio = fuzz.ratio(sentence1, sentence2)\n",
        "\n",
        "    threshold = 70\n",
        "\n",
        "    if similarity_ratio >= threshold:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AYayC5-PLURy"
      },
      "outputs": [],
      "source": [
        "def save_model_stats_to_txt(model_stats, file_path):\n",
        "    with open(file_path, 'a') as file:\n",
        "        for model_name, stats in model_stats.items():\n",
        "            file.write(f\"Model: {model_name}\\n\")\n",
        "            file.write(f\"Time Elapsed: {stats['time elapsed']} seconds\\n\")\n",
        "            file.write(f\"Total Error: {stats['total error']}\\n\")\n",
        "            file.write(f\"Total Found: {stats['total found']}\\n\")\n",
        "            file.write(f\"First Results: {stats['first results']}\\n\")\n",
        "            file.write(f\"Second Results: {stats['second results']}\\n\")\n",
        "            file.write(f\"Third Results: {stats['third results']}\\n\")\n",
        "            file.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PCi8lbZIq0Xu"
      },
      "outputs": [],
      "source": [
        "# Load input data\n",
        "INPUT_FILE_PATH = '/content/ICog-Labs/Semantic Search/data/to_kill_a_mocking_bird.txt'\n",
        "data = load_input_data(INPUT_FILE_PATH)\n",
        "\n",
        "# Convert the book into a list of sentences\n",
        "book_sentences = convert_to_sentences(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jUyPbEzqpGXG"
      },
      "outputs": [],
      "source": [
        "def run_semantic_search(model_name, model):\n",
        "    model_stats = {}\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(model_name, \"model running...\")\n",
        "\n",
        "\n",
        "    # Encode query and documents\n",
        "    if model_name == \"embed-english-v3.0\":\n",
        "      doc_emb = model.embed(book_sentences, input_type=\"search_document\", model=model_name).embeddings\n",
        "    elif model != None:\n",
        "      doc_emb = model.encode(book_sentences)\n",
        "    else:\n",
        "      doc_emb = [get_embedding(s) for s in book_sentences]\n",
        "    error = 0\n",
        "    count_first_result = 0\n",
        "    count_second_result = 0\n",
        "    count_third_result = 0\n",
        "    count_top_10 = 0\n",
        "\n",
        "    # Implementation of the semantic search logic...\n",
        "    for i, query in enumerate(questions):\n",
        "        if model_name == \"embed-english-v3.0\":\n",
        "          query_emb = model.embed([query], input_type=\"search_query\", model=model_name).embeddings\n",
        "        elif model != None:\n",
        "          query_emb = model.encode(query)\n",
        "        else:\n",
        "          query_emb = get_embedding(query)\n",
        "\n",
        "        # Compute dot score between query and all document embeddings\n",
        "        scores = compute_similarity_scores(query_emb, doc_emb)\n",
        "\n",
        "        # Combine docs & scores\n",
        "        doc_score_pairs = list(zip(book_sentences, scores))\n",
        "\n",
        "        # Sort by decreasing score\n",
        "        doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Get top-k results\n",
        "        top_k = 10\n",
        "        found = False\n",
        "\n",
        "        answer_sentences = convert_to_sentences(answers[i])\n",
        "        for j in range(1, top_k + 1):\n",
        "            for a in answer_sentences:\n",
        "              isSimmilar= check_similarity(doc_score_pairs[j][0], a)\n",
        "              if isSimmilar:\n",
        "                  error += (j - 1)\n",
        "                  found = True\n",
        "                  count_first_result += 1 if j == 1 else 0\n",
        "                  count_second_result += 1 if j == 2 else 0\n",
        "                  count_third_result += 1 if j == 3 else 0\n",
        "                  count_top_10 += 1\n",
        "                  break\n",
        "            if found:\n",
        "              break\n",
        "\n",
        "        if not found:\n",
        "            error += 15\n",
        "        # print(i + 1, \"/\", len(questions), \" error: \", error, \"count found: \", count_top_10)\n",
        "\n",
        "    end_time = time.time()\n",
        "    model_stats[model_name] = {\"time elapsed\": end_time - start_time,\n",
        "                                \"total error\": error,\n",
        "                                \"total found\": count_top_10,\n",
        "                                \"first results\": count_first_result,\n",
        "                                \"second results\": count_second_result,\n",
        "                                \"third results\": count_third_result}\n",
        "    print(model_name,\" model status \\n\", model_stats[model_name])\n",
        "\n",
        "    stats_file_path = '/content/ICog-Labs/Semantic Search/data/model_stats.txt'\n",
        "    save_model_stats_to_txt(model_stats, stats_file_path)\n",
        "\n",
        "    return model_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEoQfY3D0U_o"
      },
      "outputs": [],
      "source": [
        "def run_sbert_models(INPUT_FILE_PATH):\n",
        "    # Define constants\n",
        "    # INPUT_FILE_PATH = os.path.join(os.path.dirname(__file__), '.\\\\data\\\\to_kill_a_mocking_bird.txt')\n",
        "    MODELS = ['multi-qa-mpnet-base-dot-v1',\n",
        "              'all-mpnet-base-v2',\n",
        "              'gtr-t5-xl',\n",
        "              'all-roberta-large-v1',\n",
        "              'multi-qa-distilbert-cos-v1',\n",
        "              'all-distilroberta-v1',\n",
        "              'msmarco-bert-base-dot-v5',\n",
        "              'multi-qa-MiniLM-L6-cos-v1',\n",
        "              'msmarco-distilbert-dot-v5',\n",
        "              'all-MiniLM-L12-v2',\n",
        "              ]\n",
        "\n",
        "    # Load input data\n",
        "    data = load_input_data(INPUT_FILE_PATH)\n",
        "\n",
        "    # Convert the book into a list of sentences\n",
        "    book_sentences = convert_to_sentences(data)\n",
        "\n",
        "    # Download all models\n",
        "    download_models(MODELS)\n",
        "\n",
        "    model_stats = {}\n",
        "\n",
        "    for model_name in MODELS:\n",
        "        start_time = time.time()\n",
        "        print(model_name, \"model running...\")\n",
        "\n",
        "        # Load the model\n",
        "        model = SentenceTransformer(model_name)\n",
        "\n",
        "        # Encode query and documents\n",
        "        doc_emb = model.encode(book_sentences, convert_to_tensor=True)\n",
        "\n",
        "        error = 0\n",
        "        count_first_result = 0\n",
        "        count_second_result = 0\n",
        "        count_third_result = 0\n",
        "        count_top_10 = 0\n",
        "\n",
        "        # Implementation of the semantic search logic...\n",
        "        for i, query in enumerate(questions):\n",
        "            query_emb = model.encode(query, convert_to_tensor=True)\n",
        "\n",
        "            # Compute dot score between query and all document embeddings\n",
        "            scores = compute_similarity_scores(query_emb, doc_emb)\n",
        "\n",
        "            # Combine docs & scores\n",
        "            doc_score_pairs = list(zip(book_sentences, scores))\n",
        "\n",
        "            # Sort by decreasing score\n",
        "            doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "            # Get top-k results\n",
        "            top_k = 10\n",
        "            found = False\n",
        "            print(\"Query: \", query)\n",
        "            print(\"Answer: \", answers[i])\n",
        "            answer_sentences = convert_to_sentences(answers[i])\n",
        "            for j in range(1, top_k + 1):\n",
        "                for a in answer_sentences:\n",
        "                  isSimmilar= check_similarity(doc_score_pairs[j][0], a)\n",
        "                  if isSimmilar:\n",
        "                      error += (j - 1)\n",
        "                      found = True\n",
        "                      count_first_result += 1 if j == 1 else 0\n",
        "                      count_second_result += 1 if j == 2 else 0\n",
        "                      count_third_result += 1 if j == 3 else 0\n",
        "                      count_top_10 += 1\n",
        "                      break\n",
        "                if found:\n",
        "                  break\n",
        "\n",
        "            if not found:\n",
        "                error += 15\n",
        "            # print(i + 1, \"/\", len(questions), \" error: \", error, \"count found: \", count_top_10)\n",
        "\n",
        "        end_time = time.time()\n",
        "        model_stats[model_name] = {\"time elapsed\": end_time - start_time,\n",
        "                                   \"total error\": error,\n",
        "                                   \"total found\": count_top_10,\n",
        "                                   \"first results\": count_first_result,\n",
        "                                   \"second results\": count_second_result,\n",
        "                                   \"third results\": count_third_result}\n",
        "        print(model_name, \" model status \\n\", model_stats[model_name])\n",
        "\n",
        "    print(model_stats)\n",
        "    stats_file_path = '/content/ICog-Labs/Semantic Search/data/model_stats.txt'\n",
        "    save_model_stats_to_txt(model_stats, stats_file_path)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "By_UatCXn69g"
      },
      "outputs": [],
      "source": [
        "INPUT_FILE_PATH = '/content/ICog-Labs/Semantic Search/data/to_kill_a_mocking_bird.txt'\n",
        "run_sbert_models(INPUT_FILE_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxkwYmMv01EJ"
      },
      "outputs": [],
      "source": [
        "sbert_models_stat = {'multi-qa-mpnet-base-dot-v1': {'time elapsed': 87.76673674583435, 'total error': 117, 'total found': 16, 'first results': 6, 'second results': 2, 'third results': 2},\n",
        "                     'all-mpnet-base-v2': {'time elapsed': 89.32079792022705, 'total error': 191, 'total found': 10, 'first results': 4, 'second results': 1, 'third results': 1},\n",
        "                     'gtr-t5-xl': {'time elapsed': 1312.3310718536377, 'total error': 188, 'total found': 10, 'first results': 3, 'second results': 2, 'third results': 0},\n",
        "                     'all-roberta-large-v1': {'time elapsed': 485.50539660453796, 'total error': 234, 'total found': 7, 'first results': 1, 'second results': 1, 'third results': 1},\n",
        "                     'multi-qa-distilbert-cos-v1': {'time elapsed': 46.21957087516785, 'total error': 172, 'total found': 12, 'first results': 3, 'second results': 2, 'third results': 1},\n",
        "                     'all-distilroberta-v1': {'time elapsed': 70.17474913597107, 'total error': 206, 'total found': 9, 'first results': 0, 'second results': 4, 'third results': 2},\n",
        "                     'msmarco-bert-base-dot-v5': {'time elapsed': 96.14858531951904, 'total error': 135, 'total found': 14, 'first results': 4, 'second results': 3, 'third results': 3},\n",
        "                     'multi-qa-MiniLM-L6-cos-v1': {'time elapsed': 14.608932256698608, 'total error': 183, 'total found': 11, 'first results': 4, 'second results': 0, 'third results': 0},\n",
        "                     'msmarco-distilbert-dot-v5': {'time elapsed': 45.92693614959717, 'total error': 178, 'total found': 11, 'first results': 2, 'second results': 2, 'third results': 3},\n",
        "                     'all-MiniLM-L12-v2': {'time elapsed': 27.071072340011597, 'total error': 203, 'total found': 10, 'first results': 2, 'second results': 1, 'third results': 0}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK9CIcrZZyhG"
      },
      "source": [
        "| Model Name                     | Time Elapsed | Total Error | Total Found | First Results | Second Results | Third Results | Model Size |\n",
        "|--------------------------------|--------------|-------------|-------------|---------------|----------------|---------------|---------------|\n",
        "| multi-qa-mpnet-base-dot-v1      | 87.77s       | 117         | 16          | 6             | 2              | 2             | 420 MB |\n",
        "| msmarco-bert-base-dot-v5        | 96.15s       | 135         | 14          | 4             | 3              | 3             | 420 MB |\n",
        "| multi-qa-distilbert-cos-v1      | 46.22s       | 172         | 12          | 3             | 2              | 1             | 250 MB |\n",
        "| msmarco-distilbert-dot-v5       | 45.93s       | 178         | 11          | 2             | 2              | 3             | 250 MB |\n",
        "| multi-qa-MiniLM-L6-cos-v1       | 14.61s       | 183         | 11          | 4             | 0              | 0             | 80 MB |\n",
        "| gtr-t5-xl                       | 1312.33s     | 188         | 10          | 3             | 2              | 0             | 2370 MB |\n",
        "| all-mpnet-base-v2               | 89.32s       | 191         | 10          | 4             | 1              | 1             | 420 MB |\n",
        "| all-MiniLM-L12-v2               | 27.07s       | 203         | 10          | 2             | 1              | 0             | 120 MB |\n",
        "| all-distilroberta-v1            | 70.17s       | 206         | 9           | 0             | 4              | 2             | 290 MB |\n",
        "| all-roberta-large-v1            | 485.51s      | 234         | 7           | 1             | 1              | 1             | 1360 MB |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8Ts3oyzZ5sd"
      },
      "outputs": [],
      "source": [
        "!python -m pip install -U angle-emb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcoVQs4ejdHG"
      },
      "outputs": [],
      "source": [
        "from angle_emb import AnglE\n",
        "\n",
        "model = AnglE.from_pretrained('WhereIsAI/UAE-Large-V1', pooling_strategy='cls').cuda()\n",
        "run_semantic_search(\"UAE-Large-v1\", model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqlt_Sggta3Q"
      },
      "outputs": [],
      "source": [
        "!pip install voyageai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvc61kI92wpv"
      },
      "outputs": [],
      "source": [
        "voyageai.api_key = \"VOYAGEAI API KEY HERE\"\n",
        "\n",
        "run_semantic_search(\"voyage-lite-01-instruct\", None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9Lzc_DR3znd"
      },
      "outputs": [],
      "source": [
        "!pip install llmx\n",
        "!pip install -U cohere"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-aGkt008FlK"
      },
      "outputs": [],
      "source": [
        "import cohere\n",
        "cohere_key = \"COHERE API KEY HERE\"\n",
        "model = cohere.Client(cohere_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLXyDaCu8VSM"
      },
      "outputs": [],
      "source": [
        "run_semantic_search(\"embed-english-v3.0\", model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQ8VziKY9yqO"
      },
      "outputs": [],
      "source": [
        "model = SentenceTransformer('BAAI/bge-large-zh-v1.5')\n",
        "run_semantic_search(\"BAAI/bge-large-zh-v1.5\", model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fm3MdxM4CE0N"
      },
      "outputs": [],
      "source": [
        "model = SentenceTransformer('llmrails/ember-v1')\n",
        "run_semantic_search(\"llmrails/ember-v1\", model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPlNfG8HFlU3"
      },
      "outputs": [],
      "source": [
        "model = SentenceTransformer(\"jamesgpt1/sf_model_e5\")\n",
        "run_semantic_search(\"jamesgpt1/sf_model_e5\", model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1p-i-obcoaW3"
      },
      "outputs": [],
      "source": [
        "model = SentenceTransformer(\"thenlper/gte-large\")\n",
        "run_semantic_search(\"thenlper/gte-large\", model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbHNTzBVpOXw"
      },
      "outputs": [],
      "source": [
        "model = SentenceTransformer(\"thenlper/gte-large\")\n",
        "run_semantic_search(\"thenlper/gte-large\", model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tg4RBE9NzuUY"
      },
      "outputs": [],
      "source": [
        "model = SentenceTransformer(\"infgrad/stella-base-en-v2\")\n",
        "run_semantic_search(\"infgrad/stella-base-en-v2\", model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owQyGzOh6uhI"
      },
      "outputs": [],
      "source": [
        "!pip install InstructorEmbedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuNiuA924Lda"
      },
      "outputs": [],
      "source": [
        "from InstructorEmbedding import INSTRUCTOR\n",
        "model = INSTRUCTOR('hkunlp/instructor-xl')\n",
        "run_semantic_search(\"hkunlp/instructor-xl\", model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = INSTRUCTOR('hkunlp/instructor-large')\n",
        "run_semantic_search(\"hkunlp/instructor-large\", model)"
      ],
      "metadata": {
        "id": "1tys4UZ10Qli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = INSTRUCTOR('intfloat/e5-large-v2')\n",
        "run_semantic_search(\"intfloat/e5-large-v2\", model)"
      ],
      "metadata": {
        "id": "spZFeMuF1nUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "from transformers import AutoModel"
      ],
      "metadata": {
        "id": "Lwexba3n5aDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModel.from_pretrained('jinaai/jina-embeddings-v2-base-en', trust_remote_code=True)\n",
        "run_semantic_search(\"jinaai/jina-embeddings-v2-base-en\", model)"
      ],
      "metadata": {
        "id": "SJuQZ1zi5gtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer(\"sentence-t5-xl\")\n",
        "run_semantic_search(\"sentence-t5-xl\", model)"
      ],
      "metadata": {
        "id": "Fu55S82V8B8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  | Model                               | Time Elapsed (s) | Total Error | Total Found (21) | First Results | Second Results | Third Results |\n",
        "  |-------------------------------------|------------------|-------------|-------------|---------------|----------------|---------------|\n",
        "  | multi-qa-mpnet-base-dot-v1          | 87.77            | 117         | 16          | 6             | 2              | 2             |\n",
        "  | msmarco-bert-base-dot-v5            | 96.15            | 135         | 14          | 4             | 3              | 3             |\n",
        "  | hkunlp/instructor-xl                | 1595.49          | 158         | 14          | 2             | 0              | 3             |\n",
        "  | voyage-lite-01-instruct             | 355.76           | 166         | 12          | 2             | 5              | 0             |\n",
        "  | thenlper/gte-large                  | 340.72           | 168         | 12          | 4             | 2              | 1             |\n",
        "  | multi-qa-distilbert-cos-v1          | 46.22            | 172         | 12          | 3             | 2              | 1             |\n",
        "  | msmarco-distilbert-dot-v5           | 45.93            | 178         | 11          | 2             | 2              | 3             |\n",
        "  | multi-qa-MiniLM-L6-cos-v1           | 14.61            | 183         | 11          | 4             | 0              | 0             |\n",
        "  | hkunlp/instructor-large             | 395.49           | 188         | 11          | 1             | 2              | 2             |\n",
        "  | gtr-t5-xl                           | 1312.33          | 188         | 10          | 3             | 2              | 0             |\n",
        "  | all-mpnet-base-v2                   | 89.32            | 191         | 10          | 4             | 1              | 1             |\n",
        "  | all-MiniLM-L12-v2                   | 27.07            | 203         | 10          | 2             | 1              | 0             |\n",
        "  | cohere-embed-english-v3.0           | 10.09            | 194         | 9           | 3             | 2              | 2             |\n",
        "  | all-distilroberta-v1                | 70.17            | 206         | 9           | 0             | 4              | 2             |\n",
        "  | sentence-t5-xl                      | 1517.48          | 209         | 9           | 2             | 2              | 1             |\n",
        "  | jamesgpt1/sf_model_e5               | 341.54           | 211         | 9           | 3             | 0              | 1             |\n",
        "  | UAE-Large-v1                        | 2043.65          | 214         | 8           | 3             | 1              | 2             |\n",
        "  | llmrails/ember-v1                   | 354.12           | 216         | 8           | 1             | 3              | 0             |\n",
        "  | all-roberta-large-v1                | 485.51           | 234         | 7           | 1             | 1              | 1             |\n",
        "  | infgrad/stella-base-en-v2           | 96.30            | 241         | 7           | 1             | 0              | 2             |\n",
        "  | jinaai/jina-embeddings-v2-base-en   | 132.16           | 246         | 6           | 1             | 1              | 0             |\n",
        "  | intfloat/e5-large-v2                | 342.50           | 256         | 5           | 1             | 0              | 1             |\n",
        "  | BAAI/bge-large-zh-v1.5              | 409.35           | 266         | 5           | 0             | 0              | 1             |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3-Pvh8gcLsBg"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1POMR1jCs86oqPtlqxo3S-ary8wd8kSEt",
      "authorship_tag": "ABX9TyO6TR3U1mvBN/FWCb1G/EU1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}